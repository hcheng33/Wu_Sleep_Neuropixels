{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows Clark WS Path\n",
    "#spike_times = \"Z:/Wu_sleep/m1/SD1/20240914_SD1_test_1200_g0/catgt_20240914_SD1_test_1200_g0/20240914_SD1_test_1200_g0_imec0/imec0_ks25/spike_times.npy\"\n",
    "#spike_clusters = \"Z:/Wu_sleep/m1/SD1/20240914_SD1_test_1200_g0/catgt_20240914_SD1_test_1200_g0/20240914_SD1_test_1200_g0_imec0/imec0_ks25/spike_clusters.npy\"\n",
    "\n",
    "# mac macAir Path\n",
    "file_dir = \"/Users/alexandracheng/Desktop/Harris_Lab/Collab/Wu_Sleep/Wu_Sleep_Data/\"\n",
    "#spike_times_file = \"/Users/alexandracheng/Desktop/Harris_Lab/Collab/Wu_Sleep/Wu_Sleep_Data/spike_times_m1_1200.npy\"\n",
    "#spike_clusters_file = \"/Users/alexandracheng/Desktop/Harris_Lab/Collab/Wu_Sleep/Wu_Sleep_Data/spike_clusters_m1_1200.npy\"\n",
    "\n",
    "# parameters\n",
    "bin_size = 15000\n",
    "\n",
    "sample_rate = 30000\n",
    "sigma = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for calculating firing rate of each neuron(clsuters)\n",
    "# Input:\n",
    "# - spike_time_files = spike_times.npy\n",
    "# - spike_clusters_file = spike_clusters.npy\n",
    "# - bin_size = in sample numbers (30kHz), binwidth for calculating firing rate\n",
    "# - cluster = select for which clusters to calculate firing rate\n",
    "\n",
    "# Output:\n",
    "# - fr [cluster #, (total length/ bin width)]: binned firing rate for each cluster\n",
    "# - t_bins [(total length/ bin width),]: vector of binned time stamp\n",
    "# - clust_num [int]: number of clusters\n",
    "\n",
    "def firing_rate(spike_times_file, spike_clusters_file, bin_size, cluster):\n",
    "    spike_times = np.load(spike_times_file)\n",
    "    spike_clusters = np.load(spike_clusters_file)\n",
    "\n",
    "    if cluster == \"all\":\n",
    "        clust_ind = np.unique(spike_clusters)\n",
    "    else:\n",
    "        clust_ind = cluster\n",
    "    t_end = np.max(spike_times)\n",
    "    t_bins = np.arange(0,t_end,bin_size)\n",
    "    \n",
    "    clust_num = len(clust_ind)\n",
    "    fr = np.zeros((len(clust_ind), len(t_bins)-1))\n",
    "    for i in range(len(clust_ind)):\n",
    "        spikes_t_ind = spike_times[np.where(spike_clusters == clust_ind[i])[0]]\n",
    "        spikes_count, edges = np.histogram(spikes_t_ind, t_bins)\n",
    "\n",
    "        fr[i,:] = spikes_count\n",
    "\n",
    "    return fr, t_bins[:-1], clust_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for smoothing firing rate via gaussian filter\n",
    "# Input:\n",
    "# - fr\n",
    "# - sigma: standard deviation of gaussian kernel\n",
    "\n",
    "# Output:\n",
    "# - fr_smooth\n",
    "\n",
    "def firing_rate_smooth(fr, sigma):\n",
    "    fr_smooth = np.zeros(fr.shape)\n",
    "    for i in range(len(fr_smooth)):\n",
    "        fr_smooth[i,:] = gaussian_filter1d(fr[i,:], sigma)\n",
    "\n",
    "    return fr_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN SCRIPT FOR CALCULATING FIRING RATE\n",
    "\n",
    "# going through all the different recording sessions\n",
    "t_stamp = np.arange(900, 2200, 100)\n",
    "\n",
    "mean_fr_sessions = []\n",
    "\n",
    "for s in range(len(t_stamp)):\n",
    "    spike_times_file = file_dir + \"spike_times\"+\"_m1_\"+str(t_stamp[s])+\".npy\"\n",
    "    spike_clusters_file = file_dir + \"spike_clusters\"+\"_m1_\"+str(t_stamp[s])+\".npy\"\n",
    "\n",
    "    fr, t_bins, clust_num = firing_rate(spike_times_file, spike_clusters_file, bin_size, \"all\")\n",
    "    fr_smooth = firing_rate_smooth(fr, sigma)\n",
    "\n",
    "    # taking average of binned firing rate for each cluster\n",
    "    fr_smooth_avg = np.average(fr_smooth, axis=1)\n",
    "\n",
    "    # save total cluster fr data in vector for each session\n",
    "    mean_fr_sessions.append(fr_smooth_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_fr_sessions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
